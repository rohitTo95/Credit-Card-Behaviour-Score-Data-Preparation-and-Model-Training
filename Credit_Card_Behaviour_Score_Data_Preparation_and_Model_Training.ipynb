{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Introduction**"
      ],
      "metadata": {
        "id": "opFA43W0_xvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project involves building a predictive model to calculate a \"Behaviour Score\" for Bank A's credit card customers. The Behaviour Score predicts the likelihood of a customer defaulting on their credit card payments. The following steps outline the approach used for data preprocessing, feature selection, and model training."
      ],
      "metadata": {
        "id": "3tpHoI86_1fw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "zAcgiwZCAIbb"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load datasets\n",
        "train_file = 'training_dataset.csv'\n",
        "val_file = 'validation_dataset.csv'\n",
        "\n",
        "train_data = pd.read_csv(train_file)\n",
        "val_data = pd.read_csv(val_file)"
      ],
      "metadata": {
        "id": "VLRaZqG9ANPo"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbK4r1aZb2zJ",
        "outputId": "359aac5e-2de7-4e3e-a9dc-8c404dcfb3bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Training Set Performance:\n",
            "Accuracy: 1.00\n",
            "Precision: 0.94\n",
            "Recall: 1.00\n",
            "F1 Score: 0.97\n",
            "ROC AUC Score: 1.00\n",
            "Predictions saved to 'xgboost_predictions.csv'\n"
          ]
        }
      ],
      "source": [
        "# Separate features and target variable\n",
        "target_col = 'bad_flag'\n",
        "X_train = train_data.drop(columns=[target_col])\n",
        "y_train = train_data[target_col]\n",
        "\n",
        "# Separate features and target variable for validation dataset\n",
        "y_val = val_data[target_col] if target_col in val_data.columns else None\n",
        "X_val = val_data.drop(columns=[target_col]) if target_col in val_data.columns else val_data\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "\n",
        "\n",
        "# Get indices of features to normalize\n",
        "features_to_normalize = ['credit_activity_intensity', 'credit_limit_utilization']\n",
        "normalize_indices = [list(feature_names).index(f) for f in features_to_normalize if f in feature_names]\n",
        "\n",
        "# Normalize using indices\n",
        "scaler = StandardScaler()\n",
        "for idx in normalize_indices:\n",
        "    X_train[:, idx] = scaler.fit_transform(X_train[:, [idx]]).flatten()\n",
        "    X_val[:, idx] = scaler.transform(X_val[:, [idx]]).flatten()\n",
        "\n",
        "# Feature selection (remove low-variance features)\n",
        "selector = VarianceThreshold(threshold=0.1)\n",
        "X_train = selector.fit_transform(X_train)\n",
        "X_val = selector.transform(X_val)\n",
        "selected_features = selector.get_support(indices=True)\n",
        "feature_names = np.array(train_data.drop(columns=[target_col]).columns)[selected_features]\n",
        "\n",
        "# Train XGBoost with manual hyperparameter tuning\n",
        "scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
        "best_score = 0\n",
        "\n",
        "# Train with best parameters\n",
        "xgb_model = XGBClassifier(\n",
        "    learning_rate=0.3,\n",
        "    max_depth=6,\n",
        "    n_estimators=300,\n",
        "    scale_pos_weight=scale_pos_weight,\n",
        "    reg_alpha=0.1,\n",
        "    reg_lambda=1,\n",
        "    random_state=42,\n",
        "    eval_metric='logloss'  # Specify eval_metric here\n",
        ")\n",
        "\n",
        "if y_val is not None:\n",
        "    xgb_model.fit(\n",
        "        X_train, y_train,\n",
        "        eval_set=[(X_train, y_train), (X_val, y_val)],  # Use both training and validation sets for early stopping\n",
        "        early_stopping_rounds=10,\n",
        "        verbose=True,\n",
        "        # Remove **params from here\n",
        "    )\n",
        "else:\n",
        "    xgb_model.fit(\n",
        "        X_train, y_train,\n",
        "        verbose=True,\n",
        "        # Remove **params from here\n",
        "    )\n",
        "\n",
        "# Evaluate model on training set\n",
        "y_train_pred = xgb_model.predict(X_train)\n",
        "y_train_pred_proba = xgb_model.predict_proba(X_train)[:, 1]\n",
        "\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "train_precision = precision_score(y_train, y_train_pred)\n",
        "train_recall = recall_score(y_train, y_train_pred)\n",
        "train_f1 = f1_score(y_train, y_train_pred)\n",
        "train_roc_auc = roc_auc_score(y_train, y_train_pred_proba)\n",
        "\n",
        "print(\"XGBoost Training Set Performance:\")\n",
        "print(f\"Accuracy: {train_accuracy:.2f}\")\n",
        "print(f\"Precision: {train_precision:.2f}\")\n",
        "print(f\"Recall: {train_recall:.2f}\")\n",
        "print(f\"F1 Score: {train_f1:.2f}\")\n",
        "print(f\"ROC AUC Score: {train_roc_auc:.2f}\")\n",
        "\n",
        "# Step 7: Predict on validation dataset\n",
        "y_pred_proba = xgb_model.predict_proba(X_val)[:, 1]\n",
        "\n",
        "# Output predictions\n",
        "val_data['predicted_probability'] = y_pred_proba\n",
        "output_data = val_data[['account_number', 'predicted_probability']]\n",
        "output_data.to_csv('xgboost_predictions.csv', index=False)\n",
        "print(\"Predictions saved to 'xgboost_predictions.csv'\")\n"
      ]
    }
  ]
}